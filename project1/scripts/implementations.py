# -*- coding: utf-8 -*-
"""
Ã‰diteur de Spyder

Ceci est un script temporaire.
"""

import matplotlib.pyplot as plt
import numpy as np

def least_squares_GD(y, tx, initial_w, max_iters, gamma):
    
    """Linear regression using gradient descent
        Should return : (w,loss) 
        [last w vector + corresponding loss]
    """
    # ***************************************************
    # INSERT YOUR CODE HERE
    # TODO: Linear regression using gradient descent
    # ***************************************************
    
    raise NotImplementedError
    
def least_squares_SGD(y, tx, initial_w, max_iters, gamma):
    """Linear regression using stochastic gradient descent
        Should return : (w,loss) 
        [last w vector + corresponding loss]
    """
    # ***************************************************
    # INSERT YOUR CODE HERE
    # TODO: Linear regression using stochastic gradient descent
    # ***************************************************
    
    raise NotImplementedError

    
def least_squares(y, tx):
    """Least squares regression using normal equations
        Should return : (w,loss) 
        [last w vector + corresponding loss]
    """
    # ***************************************************
    # INSERT YOUR CODE HERE
    # TODO: Least squares regression using normal equations
    # ***************************************************
    
    raise NotImplementedError
    
    
def ridge_regression(y, tx, lambda_):
    """Ridge regression using normal equations
        Should return : (w,loss) 
        [last w vector + corresponding loss]
    """
    # ***************************************************
    # INSERT YOUR CODE HERE
    # TODO: Ridge regression using normal equations
    # ***************************************************
    
    raise NotImplementedError
    
def logistic_regression(y, tx, initial_w, max_iters, gamma):
    """Logistic regression using gradient descent or SGD
        Should return : (w,loss) 
        [last w vector + corresponding loss]
    """
    # ***************************************************
    # INSERT YOUR CODE HERE
    # TODO: Logistic regression using gradient descent or SGD
    # ***************************************************
    
    raise NotImplementedError
    
def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):
    """Regularized logistic regression using gradient descent or SGD
        Should return : (w,loss) 
        [last w vector + corresponding loss]
    """
    # ***************************************************
    # INSERT YOUR CODE HERE
    # TODO: Regularized logistic regression using gradient descent or SGD
    # ***************************************************
    
    raise NotImplementedError
    
    
    
    
    
    
    